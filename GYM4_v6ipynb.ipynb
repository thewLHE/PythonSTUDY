{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZEw4XqL4VuD"
      },
      "source": [
        "#드라이브 바운드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eS2Xp_QB03PO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcc4283-bdab-452b-ee28-4f2524d79c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2_S78dA208M"
      },
      "source": [
        "#DATA 작 해주기 - train/test/validation\n",
        "\n",
        "\n",
        "```\n",
        "1. split folder ratio 사용\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "#splitfolders.ratio('인풋경로',output='output경로' ,seed=77, ratio= (0.8,0.1,0.1)) \n",
        "#처음폴더를 output foloder(없다면 생성해준후 실행)로 train-valid-test 데이터를 0.8,0.1,0.1의 비율로 나눠줘\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaYhZPZkVWgC"
      },
      "source": [
        "#YOLO를 인식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UV8SMXRAVaMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ebe4f9d-15b8-419f-fd67-10afbc992ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "efHIM12lVg3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2f07481-ecab-4ed9-a9dc-79e8854e52fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'darkeras-yolov4'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 175 (delta 27), reused 25 (delta 23), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (175/175), 8.08 MiB | 33.34 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dhrim/darkeras-yolov4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L12zKlHSVn4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ac0d80-b890-41b7-cb5f-4ff658965071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darkeras-yolov4\n"
          ]
        }
      ],
      "source": [
        "%cd darkeras-yolov4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wVKmdV4ZVpJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fabe42-bcf7-454c-9cf3-ead9d12e2a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-12 04:21:06--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘weights/yolov3.weights’\n",
            "\n",
            "weights/yolov3.weig 100%[===================>] 236.52M  39.6MB/s    in 6.4s    \n",
            "\n",
            "2022-09-12 04:21:13 (36.8 MB/s) - ‘weights/yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O weights/yolov3.weights https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOyW9uBoVslB"
      },
      "source": [
        "##모델 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YCi3HPGCVvjp"
      },
      "outputs": [],
      "source": [
        "import yolov3_wrapper\n",
        "model = yolov3_wrapper.YoloV3Wrapper(\"weights/yolov3.weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9R_Dq1T9VxKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67bfe46-9af9-45f8-ce50-71910ab62e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "model.save(\"yolov3.h5\")#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4Kd-_pIZEV_"
      },
      "source": [
        "##이미지 로딩 \n",
        "- 이는 sit, stand를 따로 진행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cAA1H2UTY6u4"
      },
      "outputs": [],
      "source": [
        "#폴더의 모든 사진을 불러옴 - 확인용 코드(안돌려도 됨)\n",
        "# import glob\n",
        "\n",
        "# for filename in glob.glob('/gdrive/MyDrive/PROJECT/T_DATA/TRAIN_SIT/*/*.jpg'):\n",
        "#   #print(filename)\n",
        "#   name_list = filename.split(\"/\")\n",
        "#   print(name_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqXVYM0QVO3-"
      },
      "source": [
        "#OpenPose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWhIwqKGZVFs"
      },
      "source": [
        "##프로젝트 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dYPOtsCtZUkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4db8736-0c05-4087-dcbf-0889e4301742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CTQ8-mkkVOLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d574c5eb-ba65-4153-814d-8b975f72dee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Open-Pose-Keras'...\n",
            "remote: Enumerating objects: 418, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 418 (delta 11), reused 21 (delta 11), pack-reused 397\u001b[K\n",
            "Receiving objects: 100% (418/418), 29.70 MiB | 42.53 MiB/s, done.\n",
            "Resolving deltas: 100% (236/236), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dhrim/Open-Pose-Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0cMtaCm2ZfSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe48da92-c5b9-4d61-8f93-c09e3da1bc70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Open-Pose-Keras\n"
          ]
        }
      ],
      "source": [
        "%cd Open-Pose-Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqWJXqgyZigN"
      },
      "source": [
        "##install library & 모델 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yJnm6I4DZlv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5187de2-cb29-49bb-c4ea-884d5752a366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting configobj\n",
            "  Downloading configobj-5.0.6.tar.gz (33 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from configobj) (1.15.0)\n",
            "Building wheels for collected packages: configobj\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configobj: filename=configobj-5.0.6-py3-none-any.whl size=34547 sha256=334d883264552e4f057d2bdf2525c643811809f6032bd59ed78f479072096446\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/c4/19/13d74440f2a571841db6b6e0a273694327498884dafb9cf978\n",
            "Successfully built configobj\n",
            "Installing collected packages: configobj\n",
            "Successfully installed configobj-5.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install configobj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "st6wlaQYZu3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265bc1af-c3d6-4e5f-c761-bbf042b02df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d9HGnnLhq6IhC5ZSVpBf7bSrpjNj5kPB\n",
            "To: /content/Open-Pose-Keras/open_pose_model.h5\n",
            "100%|██████████| 210M/210M [00:03<00:00, 55.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "from open_pose_wrapper import OpenPoseWrapper\n",
        "model = OpenPoseWrapper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaDReQqzZ1Go"
      },
      "source": [
        "##pose detect\n",
        "- https://cmu-perceptual-computing-lab.github.io/openpose/web/html/doc/md_doc_03_python_api.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dQnEzvEejIhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e51682f-146e-405c-c183-b518396793cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Open-Pose-Keras\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Open-Pose-Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL39xKGrO5Bk"
      },
      "source": [
        "#Get angle  vlaue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMnfvcyqE5sg"
      },
      "source": [
        "##Get angle  vlaue_save.csv (09/10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f-mKFU0eZKQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d83c8aa-8e46-47d2-fb2b-199433bcbb74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /gdrive/MyDrive/PROJECT/T_DATA/A_SIT_0912_1.csv\n"
          ]
        }
      ],
      "source": [
        "#9/9\n",
        "# /gdrive/MyDrive/PROJECT/DATA0829/tmp_data/stand_0908.csv\n",
        "# FILE_Name,Neck,Hip,OuPut\n",
        "\n",
        "%%writefile /gdrive/MyDrive/PROJECT/T_DATA/A_SIT_0912_1.csv\n",
        "FILE_Name,cl1,Spin,OuPut,Error_N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-QfwxujzbY6r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "86a9de41-afcf-4e51-c6bd-425abd7af7ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [FILE_Name, cl1, Spin, OuPut, Error_N]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac038144-6e99-4cd3-9046-c8f9b837ca84\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FILE_Name</th>\n",
              "      <th>cl1</th>\n",
              "      <th>Spin</th>\n",
              "      <th>OuPut</th>\n",
              "      <th>Error_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac038144-6e99-4cd3-9046-c8f9b837ca84')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac038144-6e99-4cd3-9046-c8f9b837ca84 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac038144-6e99-4cd3-9046-c8f9b837ca84');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "cv_ad='/gdrive/MyDrive/PROJECT/T_DATA/A_SIT_0912_1.csv'\n",
        "tmp_dict=pd.read_csv (cv_ad, encoding=\"euc-kr\") \n",
        "tmp_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-XWVfYmxLWJ"
      },
      "source": [
        "추출된 점이 담긴 all_peaks는 18개의 요소가 있는 리스트이다.\n",
        "- part_str[#] :신체부위 text\n",
        "- all_peaks[1#][2#][3#] :\n",
        "    - [1#] : the people tuple data to list // 즉 한 신체부위의 값이다. 다수의 사람에 대해\n",
        "```\n",
        "(484, 130, 0.7376982569694519, 1)\n",
        "  x    y   score               point_id\n",
        "```\n",
        "    - [2#] : one person data\n",
        "    - [3#] : 한 사람의 데이터에서 특정 데이터 추출\n",
        "- 18 parts\n",
        "```\n",
        "part_str = [nose, neck, Rsho, Relb, Rwri, Lsho, Lelb, Lwri, Rhip, Rkne, Rank, Lhip, Lkne, Lank, Leye, Reye, Lear, Rear, pt19]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf9xBOQKamfi"
      },
      "source": [
        "##angle 조정을 위해 체크(확인용)\n",
        "- 09/09 우선 저장 안되는것도 다 저장가능하도록 조정\n",
        "- 09/10 오리지널 각도 조정으로 돌아가기 - if문만 조정함"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import config_reader\n",
        "import math\n",
        "from IPython.display import Image, display\n",
        "from google.colab import output\n",
        "\n",
        "#directory address\n",
        "dad='/gdrive/MyDrive/PROJECT/T_DATA/TRAIN_SIT/*/*.jpg'\n",
        "excp_list=[]#예외처리된 파일 이름 저장\n",
        "\n",
        "for file_name in glob.glob(dad): #원하는 디렉토리 경로로 변경\n",
        "\n",
        "  all_peaks,subset,candidate = model.extract(file_name)\n",
        "  model.draw_result(file_name, all_peaks, subset, candidate, draw_dot=True, draw_line=True)#\n",
        " \n",
        "  d=file_name.split(\"/\")#return list\n",
        "  pos=d[d.index(\"T_DATA\")+1].lstrip(\"TRAIN_\")\n",
        "  st=d[d.index(\"T_DATA\")+2]\n",
        "  fn=d[d.index(\"T_DATA\")+3]\n",
        "  error_n=0\n",
        "  print(\"pos\",pos,\"st\",st,\"fn\",fn,'\\n')\n",
        "  print(\"all_peaks /\",all_peaks)\n",
        "  #3\n",
        "  #part_str = [nose, neck, Rsho, Relb, Rwri, Lsho, Lelb, Lwri, Rhip, Rkne, Rank, Lhip, Lkne, Lank, Leye, Reye, Lear, Rear, pt19]\n",
        "  _, model_params = config_reader.config_reader()\n",
        "  part_str = model_params['part_str']\n",
        "\n",
        "  for i in range(18):\n",
        "    print(part_str[i], \": \", all_peaks[i])\n",
        "    #print(\"pos\",pos,\"st\",st,\"fn\",fn)\n",
        "  #4\n",
        "  #Relb가 없으면 왼쪽을 바라 본 사진임으로 Relb 유무로 사진의 좌우를 판별\n",
        "    #에러 처리\n",
        "  try:\n",
        "    if pos==\"STAND\":\n",
        "      print(\"STAND process\")\n",
        "      if not all_peaks[4]: #Rwri(팔목)가 없는 경우 - 왼쪽을 바라본 사진#stand에 관한 구역\n",
        "        if not all_peaks[-2]:#Lear이 없는 경우\n",
        "          all_peaks[-2] = all_peaks[-1]#Rear로 대치\n",
        "      #atan2(y, x) \n",
        "        neck_angle = math.degrees(math.atan2(all_peaks[5][0][1] - all_peaks[-2][0][1], all_peaks[5][0][0] - all_peaks[-2][0][0])) #어깨 - 귀(Left의 경우)\n",
        "        spine_angle = math.degrees(math.atan2(all_peaks[12][0][1] - all_peaks[5][0][1], all_peaks[12][0][0] - all_peaks[5][0][0])) #무릎 - 어깨(Left의 경우)\n",
        "        \n",
        "        sx,sy=all_peaks[5][0][0],all_peaks[5][0][1]\n",
        "        ex,ey= all_peaks[-2][0][0], all_peaks[-2][0][1]\n",
        "        kx,ky=all_peaks[12][0][0],all_peaks[12][0][1]\n",
        "      else: \n",
        "        if not all_peaks[-1]:#Rear이 없는 경우 - 왼쪽일 경우\n",
        "          all_peaks[-1] = all_peaks[-2]#Lear값으로 대치 \n",
        "        neck_angle = math.degrees(math.atan2(all_peaks[-1][0][1] - all_peaks[2][0][1], all_peaks[-1][0][0] - all_peaks[2][0][0])) #귀 - 어깨(R에 관한)\n",
        "        spine_angle = abs(math.degrees(math.atan2(all_peaks[9][0][1] - all_peaks[2][0][1], all_peaks[9][0][0] - all_peaks[2][0][0])))#무릎-어깨 (R에 관한)\n",
        "        \n",
        "        sx,sy= all_peaks[2][0][0], all_peaks[2][0][1]\n",
        "        ex,ey=all_peaks[-1][0][0],all_peaks[-1][0][1]\n",
        "        kx,ky= all_peaks[9][0][0], all_peaks[9][0][1]\n",
        "      print(fn,f\"angle: neck_angle = {neck_angle}, spine_angle = {spine_angle}\",st,\"\\n\")\n",
        "      print(error_n,\"데이터 저장 출력 stand \\n\")\n",
        "      #dt={\"FILE_Name\":[fn],\"cl1\":[str(neck_angle)],\"Spin\":[str(spine_angle)],\"OuPut\":[st],\"cl1xy\":[\"귀\",ex,ey],\"spinxy\":[\"무릎-어깨\",],\"Error_N\":error_n}#cl1,Spin,OuPut,Error_N\n",
        "      dt={\"FILE_Name\":[fn],\"cl1\":neck_angle,\"Spin\":spine_angle,\" OuPut\":[st],\"Error_N\":error_n}\n",
        "      tmp_dict=pd.DataFrame(dt)\n",
        "      tmp_dict.to_csv(cv_ad,mode='a',index=False,header=False)\n",
        "      print(\"tmp_dict: \",tmp_dict)\n",
        "    elif pos==\"SIT\"and( all_peaks[-5] and all_peaks[-8]): #about stand+ 발목까지 있는 사진 아니면 처리말자\n",
        "      print(\"SIT process\")\n",
        "      if (not all_peaks[4])and(not all_peaks[9]): #Relb가 없는 경우&&Rkne가 없는 경우 - 왼쪽을 바라본 사진 \n",
        "        if not all_peaks[-2]:\n",
        "          all_peaks[-2] = all_peaks[-1]\n",
        "      #atan2(y, x) \n",
        "        #math.radians(math.pi)#임의로 100가 넘게 나오는 경우 처리 하기위한 코드\n",
        "        knee_angle = abs(math.degrees(math.atan2(all_peaks[13][0][1] - all_peaks[11][0][1], all_peaks[13][0][0] - all_peaks[11][0][0]))) #발목-골반(Left의 경우)\n",
        "        spine_angle = abs(math.degrees(math.atan2(all_peaks[12][0][1] - all_peaks[2][0][1], all_peaks[12][0][0] - all_peaks[2][0][0]))) #무릎 - 어깨\n",
        "        if knee_angle>=100:\n",
        "          knee_angle=180-knee_angle\n",
        "        if spine_angle>=100:\n",
        "          spine_angle=180-spine_angle        \n",
        "        ankx,anky=all_peaks[13][0][0],all_peaks[13][0][1]\n",
        "        hx,hy= all_peaks[11][0][0], all_peaks[11][0][1]\n",
        "        knx,kny=all_peaks[12][0][0],all_peaks[12][0][1]\n",
        "        shx,shy= all_peaks[2][0][0], all_peaks[2][0][1]\n",
        "      else: \n",
        "        if not all_peaks[-1]:\n",
        "          all_peaks[-1] = all_peaks[-2]\n",
        "        knee_angle = abs(math.degrees(math.atan2(all_peaks[-1][0][1] - all_peaks[2][0][1], all_peaks[-1][0][0] - all_peaks[2][0][0]))) #골반-발목(R에 관한)\n",
        "        spine_angle = abs(math.degrees(math.atan2(all_peaks[9][0][1] - all_peaks[5][0][1], all_peaks[9][0][0] - all_peaks[5][0][0]))) #무릎 - 어깨\n",
        "        if knee_angle>=100:\n",
        "          knee_angle=180-knee_angle\n",
        "        if spine_angle>=100:\n",
        "          spine_angle=180-spine_angle#math.radians(math.pi)-spine_angle \n",
        "        ankx,anky=all_peaks[2][0][0],all_peaks[2][0][1]\n",
        "        hx,hy= all_peaks[-1][0][0], all_peaks[-1][0][1]\n",
        "        knx,kny=all_peaks[9][0][0],all_peaks[9][0][1]\n",
        "        shx,shy= all_peaks[5][0][0], all_peaks[5][0][1]\n",
        "      print(fn,f\"angle: knee_angle = {knee_angle}, spine_angle = {spine_angle}\",st,\"\\n\")\n",
        "      print(\"데이터 저장 출력 sit \\n\")\n",
        "      dt={\"FILE_Name\":[fn],\"cl1\":knee_angle,\"Spin\":spine_angle,\" OuPut\":[st],\"Error_N\":error_n}\n",
        "      #dt={\"FILE_Name\":[fn],\"cl1\":[str(neck_angle)],\"Spin\":[str(spine_angle)],\"OuPut\":[st],\"cl1xy\":[\"골반-발목\",hx,hy,\"-\",ankx,anky],\"spinxy\":[\"무릎-어깨\",knx,kny,\"-\",shx,shy],\"Error_N\":error_n}#cl1,Spin,OuPut,Error_N\n",
        "      tmp_dict=pd.DataFrame(dt)\n",
        "      tmp_dict.to_csv(cv_ad,mode='a',index=False,header=False)\n",
        "      print(\"tmp_dict: \",tmp_dict)\n",
        "  except IndexError:\n",
        "    error_n=3\n",
        "    print(error_n,\"데이터 저장 출력 index error \\n\")\n",
        "    dt={\"FILE_Name\":[fn],\"cl1\":\"None\",\"Spin\":\"None\",\" OuPut\":[st],\"Error_N\":error_n}\n",
        "    tmp_dict=pd.DataFrame(dt)\n",
        "    tmp_dict.to_csv(cv_ad,mode='a',index=False,header=False)\n",
        "    fn+=str(error_n)\n",
        "    excp_list.append(fn)\n",
        "    continue\n",
        "  except:\n",
        "    error_n=4\n",
        "    print(error_n,\"데이터 저장 출력 unknown error \\n\")\n",
        "    dt={\"FILE_Name\":[fn],\"cl1\":\"None\",\"Spin\":\"None\",\"OuPut\":[st],\"Error_N\":error_n}\n",
        "    tmp_dict=pd.DataFrame(dt)\n",
        "    tmp_dict.to_csv(cv_ad,mode='a',index=False,header=False)\n",
        "    fn+=str(error_n)\n",
        "    excp_list.append(fn)\n",
        "    continue\n",
        "\n",
        "print(\"ERROR종류 // 1 :sit인덱스 값 인지 안됨 || 2:stand인덱스 값 인지 안됨 || 3:이유를 찾아야 하는 에러 \")\n",
        "print(\"예외처리된 파일 이름\",excp_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VC3lMCqCGjb",
        "outputId": "d9439319-6324-4620-bca6-dde4153a530d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos SIT st BAD1 fn sit_bad_5_85.jpg \n",
            "\n",
            "all_peaks / [[(153, 112, 0.7876202911138535, 0)], [(249, 211, 0.4960874393582344, 1)], [(264, 196, 0.2743101343512535, 2)], [(180, 343, 0.1932602198794484, 3)], [(75, 404, 0.26388000324368477, 4)], [(236, 223, 0.5271507576107979, 5)], [(185, 386, 0.6403534933924675, 6)], [(77, 406, 0.5618699863553047, 7)], [(235, 443, 0.12787099136039615, 8), (236, 444, 0.12790792563464493, 9), (297, 472, 0.10619928047526628, 10)], [(35, 407, 0.16381772165186703, 11)], [], [(257, 474, 0.26201601210050285, 12)], [(23, 447, 0.4132045185833704, 13)], [], [], [(166, 93, 0.8003824949264526, 14)], [], [(215, 106, 0.8466947078704834, 15)]]\n",
            "[nose :  [(153, 112, 0.7876202911138535, 0)]\n",
            "neck :  [(249, 211, 0.4960874393582344, 1)]\n",
            "Rsho :  [(264, 196, 0.2743101343512535, 2)]\n",
            "Relb :  [(180, 343, 0.1932602198794484, 3)]\n",
            "Rwri :  [(75, 404, 0.26388000324368477, 4)]\n",
            "Lsho :  [(236, 223, 0.5271507576107979, 5)]\n",
            "Lelb :  [(185, 386, 0.6403534933924675, 6)]\n",
            "Lwri :  [(77, 406, 0.5618699863553047, 7)]\n",
            "Rhip :  [(235, 443, 0.12787099136039615, 8), (236, 444, 0.12790792563464493, 9), (297, 472, 0.10619928047526628, 10)]\n",
            "Rkne :  [(35, 407, 0.16381772165186703, 11)]\n",
            "Rank :  []\n",
            "Lhip :  [(257, 474, 0.26201601210050285, 12)]\n",
            "Lkne :  [(23, 447, 0.4132045185833704, 13)]\n",
            "Lank :  []\n",
            "Leye :  []\n",
            "Reye :  [(166, 93, 0.8003824949264526, 14)]\n",
            "Lear :  []\n",
            "Rear :  [(215, 106, 0.8466947078704834, 15)]\n",
            "pos SIT st BAD1 fn sit_bad_5_82.jpg \n",
            "\n",
            "all_peaks / [[(151, 110, 0.80567866563797, 0)], [(244, 210, 0.48115966841578484, 1)], [(251, 197, 0.24309210572391748, 2)], [(180, 335, 0.3033392410725355, 3)], [(76, 399, 0.36973312869668007, 4)], [(233, 221, 0.5318530425429344, 5), (232, 222, 0.5330107063055038, 6)], [(182, 385, 0.6515745893120766, 7)], [(78, 404, 0.5575766712427139, 8)], [(230, 444, 0.16002086631488055, 9)], [(33, 405, 0.15694550570333377, 10)], [], [(255, 476, 0.25275054038502276, 11)], [(20, 448, 0.4057068575966696, 12)], [], [], [(164, 93, 0.7839105576276779, 13)], [], [(211, 106, 0.8422096967697144, 14)]]\n",
            "[nose :  [(151, 110, 0.80567866563797, 0)]\n",
            "neck :  [(244, 210, 0.48115966841578484, 1)]\n",
            "Rsho :  [(251, 197, 0.24309210572391748, 2)]\n",
            "Relb :  [(180, 335, 0.3033392410725355, 3)]\n",
            "Rwri :  [(76, 399, 0.36973312869668007, 4)]\n",
            "Lsho :  [(233, 221, 0.5318530425429344, 5), (232, 222, 0.5330107063055038, 6)]\n",
            "Lelb :  [(182, 385, 0.6515745893120766, 7)]\n",
            "Lwri :  [(78, 404, 0.5575766712427139, 8)]\n",
            "Rhip :  [(230, 444, 0.16002086631488055, 9)]\n",
            "Rkne :  [(33, 405, 0.15694550570333377, 10)]\n",
            "Rank :  []\n",
            "Lhip :  [(255, 476, 0.25275054038502276, 11)]\n",
            "Lkne :  [(20, 448, 0.4057068575966696, 12)]\n",
            "Lank :  []\n",
            "Leye :  []\n",
            "Reye :  [(164, 93, 0.7839105576276779, 13)]\n",
            "Lear :  []\n",
            "Rear :  [(211, 106, 0.8422096967697144, 14)]\n",
            "pos SIT st BAD1 fn sit_bad_5_83.jpg \n",
            "\n",
            "all_peaks / [[(153, 113, 0.7767353355884552, 0)], [(246, 212, 0.46595825254917145, 1)], [(253, 199, 0.23865979351103306, 2)], [(181, 342, 0.18413438275456429, 3)], [(73, 404, 0.2783488780260086, 4)], [(235, 224, 0.512068621814251, 5)], [(183, 386, 0.6605450883507729, 6)], [(76, 407, 0.594150222837925, 7)], [(226, 441, 0.1475380890769884, 8)], [(33, 407, 0.1532895426498726, 9)], [], [(255, 474, 0.24920721095986664, 10)], [(23, 450, 0.36365180250504636, 11)], [], [], [(164, 94, 0.7839284539222717, 12)], [], [(213, 107, 0.8383374512195587, 13)]]\n",
            "[nose :  [(153, 113, 0.7767353355884552, 0)]\n",
            "neck :  [(246, 212, 0.46595825254917145, 1)]\n",
            "Rsho :  [(253, 199, 0.23865979351103306, 2)]\n",
            "Relb :  [(181, 342, 0.18413438275456429, 3)]\n",
            "Rwri :  [(73, 404, 0.2783488780260086, 4)]\n",
            "Lsho :  [(235, 224, 0.512068621814251, 5)]\n",
            "Lelb :  [(183, 386, 0.6605450883507729, 6)]\n",
            "Lwri :  [(76, 407, 0.594150222837925, 7)]\n",
            "Rhip :  [(226, 441, 0.1475380890769884, 8)]\n",
            "Rkne :  [(33, 407, 0.1532895426498726, 9)]\n",
            "Rank :  []\n",
            "Lhip :  [(255, 474, 0.24920721095986664, 10)]\n",
            "Lkne :  [(23, 450, 0.36365180250504636, 11)]\n",
            "Lank :  []\n",
            "Leye :  []\n",
            "Reye :  [(164, 94, 0.7839284539222717, 12)]\n",
            "Lear :  []\n",
            "Rear :  [(213, 107, 0.8383374512195587, 13)]\n",
            "pos SIT st BAD1 fn 20220817_190913_025.jpg \n",
            "\n",
            "all_peaks / [[(234, 86, 0.7511482238769531, 0)], [(135, 156, 0.6207753047347069, 1)], [(157, 171, 0.6374666765332222, 2)], [(218, 322, 0.7276778817176819, 3)], [(252, 339, 0.288095504976809, 4), (253, 340, 0.28736676648259163, 5)], [(111, 140, 0.41801220551133156, 6)], [], [], [(82, 393, 0.3050839101197198, 7)], [(274, 393, 0.6305367797613144, 8)], [(281, 604, 0.3841864339192398, 9)], [(47, 384, 0.18044864386320114, 10)], [], [], [(224, 67, 0.7960803210735321, 11)], [], [(178, 77, 0.8257699608802795, 12)], []]\n",
            "[nose :  [(234, 86, 0.7511482238769531, 0)]\n",
            "neck :  [(135, 156, 0.6207753047347069, 1)]\n",
            "Rsho :  [(157, 171, 0.6374666765332222, 2)]\n",
            "Relb :  [(218, 322, 0.7276778817176819, 3)]\n",
            "Rwri :  [(252, 339, 0.288095504976809, 4), (253, 340, 0.28736676648259163, 5)]\n",
            "Lsho :  [(111, 140, 0.41801220551133156, 6)]\n",
            "Lelb :  []\n",
            "Lwri :  []\n",
            "Rhip :  [(82, 393, 0.3050839101197198, 7)]\n",
            "Rkne :  [(274, 393, 0.6305367797613144, 8)]\n",
            "Rank :  [(281, 604, 0.3841864339192398, 9)]\n",
            "Lhip :  [(47, 384, 0.18044864386320114, 10)]\n",
            "Lkne :  []\n",
            "Lank :  []\n",
            "Leye :  [(224, 67, 0.7960803210735321, 11)]\n",
            "Reye :  []\n",
            "Lear :  [(178, 77, 0.8257699608802795, 12)]\n",
            "Rear :  []\n",
            "pos SIT st BAD1 fn 20220817_190913_006.jpg \n",
            "\n",
            "all_peaks / [[(245, 45, 0.8807151466608047, 0)], [(140, 91, 0.6006222814321518, 1)], [(165, 114, 0.5392970964312553, 2)], [(213, 261, 0.6610345467925072, 3)], [], [(114, 64, 0.4116428755223751, 4)], [], [], [(66, 300, 0.2496298886835575, 5)], [(256, 300, 0.5749007761478424, 6)], [(261, 507, 0.2901567067601718, 7)], [(35, 290, 0.11419002252659993, 8)], [], [], [(229, 24, 0.8582951426506042, 9)], [(257, 30, 0.8578689396381378, 10)], [(179, 23, 0.7571431547403336, 11)], []]\n",
            "[nose :  [(245, 45, 0.8807151466608047, 0)]\n",
            "neck :  [(140, 91, 0.6006222814321518, 1)]\n",
            "Rsho :  [(165, 114, 0.5392970964312553, 2)]\n",
            "Relb :  [(213, 261, 0.6610345467925072, 3)]\n",
            "Rwri :  []\n",
            "Lsho :  [(114, 64, 0.4116428755223751, 4)]\n",
            "Lelb :  []\n",
            "Lwri :  []\n",
            "Rhip :  [(66, 300, 0.2496298886835575, 5)]\n",
            "Rkne :  [(256, 300, 0.5749007761478424, 6)]\n",
            "Rank :  [(261, 507, 0.2901567067601718, 7)]\n",
            "Lhip :  [(35, 290, 0.11419002252659993, 8)]\n",
            "Lkne :  []\n",
            "Lank :  []\n",
            "Leye :  [(229, 24, 0.8582951426506042, 9)]\n",
            "Reye :  [(257, 30, 0.8578689396381378, 10)]\n",
            "Lear :  [(179, 23, 0.7571431547403336, 11)]\n",
            "Rear :  []\n",
            "pos SIT st BAD1 fn 20220817_190913_024.jpg \n",
            "\n",
            "all_peaks / [[(241, 84, 0.7409705966711044, 0)], [(138, 148, 0.6258597746491432, 1)], [(162, 165, 0.6259340569376945, 2)], [(221, 318, 0.6340064406394958, 3)], [(257, 349, 0.22795428521931171, 4)], [(113, 129, 0.41880179941654205, 5)], [], [], [(76, 380, 0.2991287314798683, 6)], [(269, 381, 0.5996865443885326, 7)], [(276, 595, 0.39326984307263047, 8)], [(41, 369, 0.1812837366014719, 9)], [], [], [(233, 65, 0.7665826231241226, 10)], [], [(185, 73, 0.8366854041814804, 11)], []]\n",
            "[nose :  [(241, 84, 0.7409705966711044, 0)]\n",
            "neck :  [(138, 148, 0.6258597746491432, 1)]\n",
            "Rsho :  [(162, 165, 0.6259340569376945, 2)]\n",
            "Relb :  [(221, 318, 0.6340064406394958, 3)]\n",
            "Rwri :  [(257, 349, 0.22795428521931171, 4)]\n",
            "Lsho :  [(113, 129, 0.41880179941654205, 5)]\n",
            "Lelb :  []\n",
            "Lwri :  []\n",
            "Rhip :  [(76, 380, 0.2991287314798683, 6)]\n",
            "Rkne :  [(269, 381, 0.5996865443885326, 7)]\n",
            "Rank :  [(276, 595, 0.39326984307263047, 8)]\n",
            "Lhip :  [(41, 369, 0.1812837366014719, 9)]\n",
            "Lkne :  []\n",
            "Lank :  []\n",
            "Leye :  [(233, 65, 0.7665826231241226, 10)]\n",
            "Reye :  []\n",
            "Lear :  [(185, 73, 0.8366854041814804, 11)]\n",
            "Rear :  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t87zcE6rbGFZ"
      },
      "source": [
        "##파일 출력하는 기능[csv]\n",
        "- tmp (9/6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxzMaY3ZbNXi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "#directory address\n",
        "#dad='/gdrive/MyDrive/PROJECT/DATA0829/SIT1500/TRAIN/*/*.jpg'\n",
        "\n",
        "for file_name in glob.glob(cv_ad):\n",
        "  with open(file_name, newline='', encoding='utf-8') as f:\n",
        "      reader = csv.reader(f)#to_csv로 바꾸기\n",
        "      for row in reader:\n",
        "          print(row)#저장을 해야할까 바로 불러서 쓰는 방식을 이용해야 하는지 고민해야 할것 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnlQEnFRqhAK"
      },
      "source": [
        "##all peaks print / 확인용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2fZI0pEaNV6"
      },
      "outputs": [],
      "source": [
        "import config_reader\n",
        "\n",
        "_, model_params = config_reader.config_reader()\n",
        "part_str = model_params['part_str']\n",
        "for i in range(18):\n",
        "  print(part_str[i], \": \", all_peaks[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cVDjeCEaWqA"
      },
      "outputs": [],
      "source": [
        "#기존 예시 코드 - 실행 x\n",
        "model.extract_and_draw(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4t3V9SEaeSE"
      },
      "outputs": [],
      "source": [
        "print(len(all_peaks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdOGxMg7aan7"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n",
        "###all peaks print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boygmKC6agUA"
      },
      "outputs": [],
      "source": [
        "import config_reader\n",
        "\n",
        "_, model_params = config_reader.config_reader()\n",
        "part_str = model_params['part_str']\n",
        "for i in range(18):\n",
        "  print(part_str[i], \": \", all_peaks[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiv9ZYIbakk9"
      },
      "source": [
        "\n",
        "- 1개의 point는 다음과 같이 구성된다.\n",
        "```\n",
        "(484, 130, 0.7376982569694519, 1)\n",
        "  x    y   score               point_id\n",
        "```\n",
        "- point_id는 all_peaks에 명시되어 있다.\n",
        "\n",
        "```\n",
        "all_peaks의 내용\n",
        "\n",
        "(177, 6, 0.11634597013471648, 0)\n",
        "(484, 130, 0.7376982569694519, 1)\n",
        "(287, 154, 0.9168482273817062, 2)\n",
        "(410, 221, 0.9359188675880432, 3)\n",
        "\n",
        "각 줄의 마지막 숫자가 point_id이다.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joTx4Cnbam3s"
      },
      "source": [
        "subset의 경우 이미지에서 한 사람의 값을 가진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJRv80HEa65I"
      },
      "source": [
        "각 포인트별 연결 가능 여부는 limSeq에 담겨 있다.\n",
        "\n",
        "\n",
        "\n",
        "[2, 3] 은 neck과 Rsho(righst shoulder)가 연결되어 있음을 의미하고, \n",
        "\n",
        "[3,4]는 Rsho(righst shoulder)와 Relb(right elbow)가 이어져 있다는 것을 의미한다.\n",
        "\n",
        "```\n",
        "1: nose\n",
        "2: neck\n",
        "3: Rsho\n",
        "4: Relb\n",
        "5: Rwri\n",
        "...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtChU3CVO9c6"
      },
      "source": [
        "#Save&Load .csv file data\n",
        "\n",
        "\n",
        "```\n",
        "x, y, NA, SA, class1, class2\n",
        "\n",
        "```\n",
        "- if the vlaue not exist- > 0 or None\n",
        "-  참고자료 \n",
        "https://colab.research.google.com/github/datascienceschool/book/blob/master/ds/01%20python/04.02%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%9E%85%EC%B6%9C%EB%A0%A5.ipynb#scrollTo=ZQxwXT9GP-4A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyrJ8t0VQ9_E"
      },
      "source": [
        "`%%writefile` 매직(magic) 명령으로 만들어보자. 이 명령은 셀에 서술한 내용대로 텍스트 파일을 만드는 명령이다.\n",
        "```\n",
        "%%writefile STAND_TRAIN.csv\n",
        "x, y, NA, SA, class1, class2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJFRG75MRVvP"
      },
      "source": [
        "## CSV파일로부터 데이터를 읽어 데이터 프레임을 만들 때\n",
        "- CSV 파일로부터 데이터를 읽어 데이터프레임을 만들 때는 `pandas.read_csv` 함수를 사용한다. 함수의 입력값으로 파일 이름을 넣는다.\n",
        "- 확장자가 CSV가 아닌 파일 즉, 데이터를 구분하는 구분자(separator)가 쉼표(comma)가 아니면 `sep` 인수를 써서 구분자를 사용자가 지정해준다. 만약 길이가 정해지지 않은 공백이 구분자인 경우에는 `\\s+` 정규식(regular expression) 문자열을 사용한다.\n",
        "- 만약 자료 파일 중에 건너 뛰어야 할 행이 있으면 ```skiprows ```인수를 read_csv함수에 적용하여 이용\n",
        "- 특정한 값을 NaN으로 취급하고 싶으면 `na_values` 인수에 NaN 값으로 취급할 값을 넣는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnXqPLlsRJyj"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('STAND_TRAIN.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlPHb-aJT_KD"
      },
      "outputs": [],
      "source": [
        "#pd.read_table('STAND_TRAIN.txt', sep='\\s+')#pd.read_csv('sample4.txt', skiprows=[0, 1])\n",
        "#df = pd.read_csv('sample5.csv', na_values=['누락'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA8JXLycUnB-"
      },
      "source": [
        "##CSV파일 출력\n",
        "- `to_csv` 메서드를 사용한다.(cat과 비슷하게 인자를 추가해서 이용이 가능)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icPgphWcyd2u"
      },
      "source": [
        "#Vanilla CNN Template\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3g9RX2BS7oV"
      },
      "source": [
        "##모듈임포팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PjQAtOCyco0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import GaussianNoise\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.applications import efficientnet\n",
        "from tensorflow.keras.applications import EfficientNetB2\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcX4sUfDS4o9"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Input((224,224,3)))\n",
        "model.add(GaussianNoise(0.1))\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(Conv2D(64, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3,3), padding='same'))\n",
        "model.add(Conv2D(128, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(Conv2D(256, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq3wSN5LwWth"
      },
      "outputs": [],
      "source": [
        "#다중분류\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"Adam\", metrics=['acc'])\n",
        "#good,bad만 분류하면되니까 2진분류\n",
        "# model.compile(loss='binary_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "def normalize(image):\n",
        "  return image/255.0\n",
        "\n",
        "preprocessor = normalize\n",
        "BATCH_SIZE = 64 # BATCH_SIZE = 128\n",
        "\n",
        "train_data_generator = ImageDataGenerator(#이미지 augmentation(증가) / return v - 입력이 변형된 상태\n",
        "      rotation_range=5, #bad1~4,good 5개\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=False,\n",
        "      preprocessing_function=preprocessor\n",
        ").flow_from_directory(#이미지가 저장된 폴더를 기준으로 라벨 정보와 함께 이미지를 불러들임\n",
        "      \"/gdrive/MyDrive/PROJECT/DATA0829/STAND1500/TRAIN\",#학습시킬 경로\n",
        "      target_size=(224,224),#이미지 크기 fix - 넘어가게 되면 그래픽 에러 남\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        ")\n",
        "\n",
        "test_data_generator = ImageDataGenerator(\n",
        "      preprocessing_function=preprocessor#이미지 처리전에 주어진 값을곱해 크기를 조정.    \n",
        ").flow_from_directory(\n",
        "      \"/gdrive/MyDrive/PROJECT/DATA0829/STAND1500/TEST\", #test경로\n",
        "      target_size=(224,224),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHDruxJ7wwwC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model_check_point = ModelCheckpoint(\n",
        "    'pose_best_model.h5', \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True)\n",
        "#모델체크포인트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TIWmkkG27Vz"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "      train_data_generator,\n",
        "      validation_data=test_data_generator,\n",
        "      steps_per_epoch=train_data_generator.samples/BATCH_SIZE,\n",
        "      validation_steps=test_data_generator.samples/BATCH_SIZE,      \n",
        "      epochs=100, callbacks=[model_check_point]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKcUQN2KSsEp"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('pose_best_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIvMXsI6bUz-"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(\n",
        "      test_data_generator,\n",
        "      steps=test_data_generator.samples/BATCH_SIZE\n",
        ")\n",
        "print(\"loss=\", loss)\n",
        "print(\"acc=\", acc)\n",
        "\n",
        "\n",
        "\n",
        "test_x, test_y = next(iter(test_data_generator))\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=-1)\n",
        "\n",
        "plt.plot(test_y[:100], \"o\")\n",
        "plt.plot(predicted[:100], '.')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7d9neMj38kA"
      },
      "source": [
        "https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/save_and_load.ipynb?hl=ko\n",
        "\n",
        "참고 사이트"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}